<!DOCTYPE html>
<html>
<head></head>
<body>
	
  <h1 style='text-align: center; margin-bottom: -35px;'>Image labeling webapp</h1>
  <br><br>
	
	
<!-- OCR webapp -->
<!-- https://js.tensorflow.org/api/1.0.0/ -->
<!-- https://www.jsdelivr.com/?query=author%3A%20tensorflow&page=1 -->
	
   <h2 id="select_model" style='text-align: left; display:none'>Write a captial letter or number in the box, click the button to classify</h2>
   
		
<!-- Once image and model are selected, make image appear in canvas and run model -->
   <div style="width:100%;height:100%;position:absolute;vertical-align:middle;text-align:left;">
        <canvas id="canvasId" width="224" height="224" style="display:block"></canvas>
    <div>

      <div style="width:100%;height:100%;position:absolute;vertical-align:middle;text-align:left;">
        <button id="run_object_detection" onclick="run_object_detection()" style="display:block">run_object_detection</button>
    <div>

    <div id="output" style="font-family:courier;font-size:24px;height:300px"></div>

	    
<style>
      canvas {border: 1px solid black;}
    </style>
  
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script> 

  
<script>
  // https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/drawImage
  var canvasElement = document.getElementById("canvasId");
  const ctx = canvasElement.getContext("2d");

  // -------------------------------------------------
	
  const outp = document.getElementById('output');

  // -------------------------------------------------

	  var maxX = 0;
  var maxY = 0;
  var minX = 0;
  var minY = 0;
	var boundingbox_vec = [];

	
  // -------------------------------------------------
	
  // https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent/clientX
  // eventlistener for mousedown
	
  canvasElement.addEventListener("mousedown", (e) => {
     ctx.lineTo(e.offsetX, e.offsetY);
     ctx.lineWidth = 10;  // thickness of line
     ctx.beginPath();
     canvasElement.addEventListener("mousemove", createlines, false);

     if (e.offsetX > maxX) {
        maxX = e.offsetX;
     }
     if (e.offsetY > maxY) {
        maxY = e.offsetY;
     }
     if (e.offsetX < minX) {
        minX = e.offsetX;
     }
     if (e.offsetY < minY) {
        minY = e.offsetY;
     }
			 
  }, false);
	


  var createlines = function(e){

     // https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent/pageX
     // returns the X (horizontal) coordinate (in pixels) at which the mouse was clicked, relative to the left edge of the entire document (close)
     // ctx.lineTo(e.pageX-e.offsetX, e.pageY-e.offsetY);
     // OR
     // the horizontal/vertical coordinate (offset) of the mouse pointer in screen coordinates. (not correct)
     // ctx.lineTo(e.screenX, e.screenY);
     // OR
     // the horizontal coordinate within the application's viewport at which the event occurred (as opposed to the coordinate within the page). (close)
     // ctx.lineTo(e.clientX, e.clientY);
     // OR
     // provides the offset in the X coordinate of the mouse pointer between that event and the padding edge of the target node. (CORRECT!!)
     ctx.lineTo(e.offsetX, e.offsetY);
	  
     ctx.strokeStyle = "green";  // color of line
     ctx.stroke();
  };
	
  // -------------------------------------------------
	
  canvasElement.addEventListener("mouseup", () => {

     canvasElement.removeEventListener('mousemove', createlines, false);

     const img = new Image();
     img.onload = () => {
     ctx.drawImage(img, 0, 0, 224, 224);
     };

     outp.innerHTML += "maxX=" + maxX + " : " +  "maxY=" + maxY + " : " +  "minX=" + minX + " : " +  "minY=" + minY;

     // Put each box in a vector: [x_start_topleft, y_start_top_left, width, height]
     //The rectangle's width. Positive values are to the right, and negative to the left.
     //width = maxX - minX;
     // The rectangle's height. Positive values are down, and negative are up.
     //height = maxY - minY;
     boundingbox_vec.push([maxX, minY, maxX - minX, maxY - minY])

	
	  outp.innerHTML += "test to see if variables are accumulating in boundingbox_vec:  boundingbox_vec.length=" + boundingbox_vec.length;
	  // for(var i = 0; i<boundingbox_vec.length; i++){
	  //   for(var j = 0; i<4; i++){
	 //    	outp.innerHTML += boundingbox_vec[i][j] + ",";
	 //    }
	  //   outp.innerHTML += "<br/>";
     //}
	  
     ctx.beginPath();
      ctx.lineWidth = '2';
      ctx.strokeStyle = 'red';
      ctx.fillStyle = 'red';
      ctx.rect(maxX, minY, maxX - minX, maxY - minY);
     ctx.stroke();

     maxX = 0;
     maxY = 0;
     minX = 0;
     minY = 0;
	  
  }, false);

  // -------------------------------------------------

  async function run_object_detection(){

     try {
      
     // outp.innerHTML = canvasElement.toDataURL();

      // -------------------------------------------------
      // Way 0
      await cocoSsd.load().then(model => {
	
        // ----------------------
        // Test if it has received the image

        // const image = new Image();
        // image.src = canvasElement.toDataURL();  // This gives the url to the image drawn on the canvas
        // ctx.drawImage(image, 0, 0, 224, 224);
        // var tensor_image = tf.browser.fromPixels(image); // This is size 224,224,3
	
	// Error: Requested texture size [0x0] is invalid.

        // OR
	
        // const tensor_image = tf.browser.fromPixels(canvasElement); // This is size 224,224,3

	// OR

	const image = new Image();
	image.src = canvasElement.toDataURL();  // This gives the url to the image drawn on the canvas
	image.onload = async () => {
		ctx.drawImage(image, 0, 0, 224, 224);
		ctx.beginPath();
		ctx.strokeStyle = "red";  // color of line
		
		var tensor_image = tf.browser.fromPixels(image); // This is size 224,224,3
		outp.innerHTML = tf.max(tensor_image);

		// model.detect(image).then(predictions => { outp.innerHTML = 'Here1: ' + predictions; }); 
		// OR
		// await model.detect(image).then(predictions => {for(var i = 0; i<predictions.length; i++){outp.innerHTML += "<br/>" + predictions[i].bbox + " : " + predictions[i].class + " : " + predictions[i].score;} });


		// OR
		await model.detect(image).then(predictions => { predictions.forEach(prediction => {
      ctx.beginPath();
      ctx.lineWidth = '2';
      ctx.strokeStyle = 'red';
      ctx.fillStyle = 'red';
      ctx.rect(
        prediction.bbox[0],
        prediction.bbox[1],
        prediction.bbox[2],
        prediction.bbox[3]
      );
      ctx.stroke();
      ctx.fillText(
        `${prediction.class} (${Math.round(prediction.score * 100)}%)`,
        prediction.bbox[0],
        prediction.bbox[1] > 10 ? prediction.bbox[1] - 5 : 10
      );
    }); });



		
	  };
        // ----------------------

        // const image_4D = tensor_image.expandDims(0); // This is size 1,224,224,3
	// Uncaught (in promise) Error: The shape of dict['image_tensor'] provided in model.execute(dict) must be [-1,-1,-1,3], but was [1,1,224,224,3]

	// const tensor_image_int = tf.cast(tensor_image, 'int32')
	// Error: The dtype of dict['image_tensor'] provided in model.execute(dict) must be int32, but was float32

        // ----------------------
	      
        // 
	      
	// outp.innerHTML = tf.max(tensor_image_int);
	// No response

        // ----------------------

        // Give image to model
        // model.detect(image).then(predictions => { outp.innerHTML = predictions; }); 

        // ----------------------
	});  // end of await cocoSsd.load
		  
	// -------------------------------------------------
		  
	// OR

	// -------------------------------------------------
	// Way 1
	// await cocoSsd.load().then(model => { model.detect(image).then(predictions => { outp.innerHTML = predictions; }); });
	// -------------------------------------------------  

    } catch (error) {
      outp.innerHTML = error
    }

  }

  // -------------------------------------------------



	

</script>
</body>
</html>
