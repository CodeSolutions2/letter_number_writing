<!DOCTYPE html>
<html>
<head></head>
<body>
	
  <h1 style='text-align: center; margin-bottom: -35px;'>Image labeling webapp</h1>
  <br><br>
	
	
<!-- OCR webapp -->
<!-- https://js.tensorflow.org/api/1.0.0/ -->
<!-- https://www.jsdelivr.com/?query=author%3A%20tensorflow&page=1 -->
	
   <h2 id="select_model" style='text-align: left; display:none'>Write a captial letter or number in the box, click the button to classify</h2>
   
		
<!-- Once image and model are selected, make image appear in canvas and run model -->
   <div style="width:100%;height:100%;position:absolute;vertical-align:middle;text-align:left;">
        <canvas id="canvasId" width="224" height="224" style="display:block"></canvas>
    <div>

      <div style="width:100%;height:100%;position:absolute;vertical-align:middle;text-align:left;">
        <button id="run_object_detection" onclick="run_object_detection()" style="display:block">run_object_detection</button>&nbsp;&nbsp;&nbsp;
        <button id="cut_images_using_boundingboxes" onclick="cut_images_using_boundingboxes()" style="display:block">cut_images_using_boundingboxes</button>
    <div>

    <div id="output" style="font-family:courier;font-size:24px;height:300px"></div>

	    
<style>
      canvas {border: 1px solid black;}
    </style>
  
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script> 

  
<script>
  // https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/drawImage
  var canvasElement = document.getElementById("canvasId");
  const ctx = canvasElement.getContext("2d");

  // -------------------------------------------------
	
  const outp = document.getElementById('output');

  // -------------------------------------------------

  var maxX = 0;
  var maxY = 0;
  var minX = 255;
  var minY = 255;
  var width = maxX-minX;
  var height = minY-maxY;
  var boundingbox_vec = [];
  var padboundary = 20;
  var x_start_bottomleft_corner = minX - padboundary/2;
  var y_start_bottomleft_corner = maxY + padboundary/2;

  // -------------------------------------------------
	
  // https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent/clientX
  // eventlistener for mousedown
	
  canvasElement.addEventListener("mousedown", (e) => {
     ctx.lineTo(e.offsetX, e.offsetY);
     ctx.lineWidth = 10;  // thickness of line
     ctx.beginPath();
     canvasElement.addEventListener("mousemove", createlines, false);
			 
  }, false);
	


  var createlines = function(e){

     // https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent/pageX
     // returns the X (horizontal) coordinate (in pixels) at which the mouse was clicked, relative to the left edge of the entire document (close)
     // ctx.lineTo(e.pageX-e.offsetX, e.pageY-e.offsetY);
     // OR
     // the horizontal/vertical coordinate (offset) of the mouse pointer in screen coordinates. (not correct)
     // ctx.lineTo(e.screenX, e.screenY);
     // OR
     // the horizontal coordinate within the application's viewport at which the event occurred (as opposed to the coordinate within the page). (close)
     // ctx.lineTo(e.clientX, e.clientY);
     // OR
     // provides the offset in the X coordinate of the mouse pointer between that event and the padding edge of the target node. (CORRECT!!)
     ctx.lineTo(e.offsetX, e.offsetY);
	  
     ctx.strokeStyle = "green";  // color of line
     ctx.stroke();

     if (e.offsetX > maxX) {
        maxX = e.offsetX;
     } else {
        maxX = maxX; 
     }
     if (e.offsetY > maxY) {
        maxY = e.offsetY;
     } else {
        maxY = maxY; 
     }
     if (e.offsetX < minX) {
        minX = e.offsetX;
     } else {
        minX = minX; 
     }
     if (e.offsetY < minY) {
        minY = e.offsetY;
     } else {
        minY = minY; 
     }
  };
	
  // -------------------------------------------------
	
  canvasElement.addEventListener("mouseup", () => {

     canvasElement.removeEventListener('mousemove', createlines, false);

     const img = new Image();
     img.onload = () => {
     ctx.drawImage(img, 0, 0, 224, 224);
     };

     outp.innerHTML = "";
     outp.innerHTML += "maxX=" + maxX + " : " +  "maxY=" + maxY + " : " +  "minX=" + minX + " : " +  "minY=" + minY + "<br/>";

     // Put each box in a vector: [x_start_bottomleft_corner, y_start_bottomleft_corner, width, height]
     x_start_bottomleft_corner = minX - padboundary/2;
     y_start_bottomleft_corner = maxY + padboundary/2;
	  
     //The rectangle's width. Positive values are to the right, and negative to the left.  
     width = maxX-minX;

     // The rectangle's height. Positive values are down, and negative are up.
     height = minY-maxY; 
     if (width < 0){
        width = width - padboundary/2;
     } else {
        width = width + padboundary/2;
     }

     if (height < 0){
        height = height - padboundary/2;
     } else {
        height = height + padboundary/2;
     }
     
     boundingbox_vec.push([x_start_bottomleft_corner, y_start_bottomleft_corner, width, height])

     // values accumulate in boundingbox_vec
     outp.innerHTML += "boundingbox_vec:" + "<br/>";
     for(var i = 0; i<boundingbox_vec.length; i++){
        for(var j = 0; j<4; j++){
          outp.innerHTML += boundingbox_vec[i][j] + ",";
        }	
        outp.innerHTML += "<br/>";
     }
	  
     ctx.beginPath();
     ctx.lineWidth = '2';
     ctx.strokeStyle = 'red';
     ctx.fillStyle = 'red';
     ctx.rect(x_start_bottomleft_corner, y_start_bottomleft_corner, width, height);
     ctx.stroke();

     maxX = 0;
     maxY = 0;
     minX = 255;
     minY = 255;
	  
  }, false);

  // -------------------------------------------------

  async function cut_images_using_boundingboxes() {

	  const MODEL_URL = 'model.json';
        const model = await tf.loadLayersModel(MODEL_URL);
	  
	  // Obtain image from canvas
	  const image = new Image();
	image.src = canvasElement.toDataURL();  // This gives the url to the image drawn on the canvas
	  
	image.onload = async () => {
		ctx.drawImage(image, 0, 0, 224, 224);
		// ctx.beginPath(); // did not work
		// ctx.strokeStyle = "red";  // color of line  // did not work

		outp.innerHTML += 'here0';
		var tensor_image = tf.browser.fromPixels(image); // This is size 224,224,3
		outp.innerHTML = tf.max(tensor_image);

		const image_4D = tensor_image.expandDims(0); // This is size 1,224,224,3

		// const image_4D_float = tf.cast(image_4D, 'float32')
		
		// Make image values from 0 to 1
		// const b = tf.scalar(255);
		// const image_4D_scaled0to1 = image_4D.div(b)
		const shape_out = image_4D.shape;
		
		// Ensure that tensor is 4d
		const x = tf.reshape(image_4D, [1, shape_out[1], shape_out[2], shape_out[3]])
outp.innerHTML += 'here2';
		
		// -----------------------------------------------
		var boxes = tf.tensor2d([boundingbox_vec[0]], [1, 4]);  // initialize variable
		const boxIndices = tf.tensor1d([0], 'int32');
		const newSize = [28, 28];
		var resizedTensor = tf.image.cropAndResize(x, boxes, boxIndices, newSize);  // initialize variable
		
		for (var i = 0; i<boundingbox_vec.length; i++){
			// select each bounding box and make a tensor
			outp.innerHTML += 'boundingbox_vec ' + i;
				
			boxes = tf.tensor2d([boundingbox_vec[i]], [1, 4]);
			resizedTensor = tf.image.cropAndResize(x, boxes, boxIndices, newSize);
	
			// To confirm, would need to: convert the tensor to Image, then create a canvas, then drawImage to canvas

			// -----------------------------------------------
			// Give image to model
			const result = model.predict(resizedTensor); 
			outp.innerHTML += result.argMax();
			
		} // end of for
	  

	}  // end of image.onload
  }
	
  // -------------------------------------------------


  async function run_object_detection(){

     try {
      
     // outp.innerHTML = canvasElement.toDataURL();

      // -------------------------------------------------
      // Way 0
      await cocoSsd.load().then(model => {
	
        // ----------------------
        // Test if it has received the image

        // const image = new Image();
        // image.src = canvasElement.toDataURL();  // This gives the url to the image drawn on the canvas
        // ctx.drawImage(image, 0, 0, 224, 224);
        // var tensor_image = tf.browser.fromPixels(image); // This is size 224,224,3
	
	// Error: Requested texture size [0x0] is invalid.

        // OR
	
        // const tensor_image = tf.browser.fromPixels(canvasElement); // This is size 224,224,3

	// OR

	const image = new Image();
	image.src = canvasElement.toDataURL();  // This gives the url to the image drawn on the canvas
	image.onload = async () => {
		ctx.drawImage(image, 0, 0, 224, 224);
		ctx.beginPath();
		ctx.strokeStyle = "red";  // color of line
		
		var tensor_image = tf.browser.fromPixels(image); // This is size 224,224,3
		outp.innerHTML = tf.max(tensor_image);

		// model.detect(image).then(predictions => { outp.innerHTML = 'Here1: ' + predictions; }); 
		// OR
		// await model.detect(image).then(predictions => {for(var i = 0; i<predictions.length; i++){outp.innerHTML += "<br/>" + predictions[i].bbox + " : " + predictions[i].class + " : " + predictions[i].score;} });


		// OR
		await model.detect(image).then(predictions => { predictions.forEach(prediction => {
      ctx.beginPath();
      ctx.lineWidth = '2';
      ctx.strokeStyle = 'red';
      ctx.fillStyle = 'red';
      ctx.rect(
        prediction.bbox[0],
        prediction.bbox[1],
        prediction.bbox[2],
        prediction.bbox[3]
      );
      ctx.stroke();
      ctx.fillText(
        `${prediction.class} (${Math.round(prediction.score * 100)}%)`,
        prediction.bbox[0],
        prediction.bbox[1] > 10 ? prediction.bbox[1] - 5 : 10
      );
    }); });



		
	  };
        // ----------------------

        // const image_4D = tensor_image.expandDims(0); // This is size 1,224,224,3
	// Uncaught (in promise) Error: The shape of dict['image_tensor'] provided in model.execute(dict) must be [-1,-1,-1,3], but was [1,1,224,224,3]

	// const tensor_image_int = tf.cast(tensor_image, 'int32')
	// Error: The dtype of dict['image_tensor'] provided in model.execute(dict) must be int32, but was float32

        // ----------------------
	      
        // 
	      
	// outp.innerHTML = tf.max(tensor_image_int);
	// No response

        // ----------------------

        // Give image to model
        // model.detect(image).then(predictions => { outp.innerHTML = predictions; }); 

        // ----------------------
	});  // end of await cocoSsd.load
		  
	// -------------------------------------------------
		  
	// OR

	// -------------------------------------------------
	// Way 1
	// await cocoSsd.load().then(model => { model.detect(image).then(predictions => { outp.innerHTML = predictions; }); });
	// -------------------------------------------------  

    } catch (error) {
      outp.innerHTML = error
    }

  }

  // -------------------------------------------------



	

</script>
</body>
</html>
